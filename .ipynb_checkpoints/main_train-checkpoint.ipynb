{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from nlp_db import nlp_db\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2124000\r\n",
      "-rw-r--r--  1 root  staff   21695199 Jun  7 13:48 xiaohuangji.tsv\r\n",
      "-rw-r--r--  1 root  staff  465372773 Jun  7 13:48 weibo.tsv\r\n",
      "-rw-r--r--  1 root  staff  298597018 Jun  7 13:46 tieba.tsv\r\n",
      "-rw-r--r--  1 root  staff  151548740 Jun  7 13:46 subtitle.tsv\r\n",
      "-rw-r--r--  1 root  staff    5594328 Jun  7 13:45 qingyun.tsv\r\n",
      "-rw-r--r--  1 root  staff   18202714 Jun  7 13:45 ptt.tsv\r\n",
      "-rw-r--r--  1 root  staff      34249 Jun  7 13:44 chatterbot.tsv\r\n",
      "-rw-r--r--  1 root  staff   85680288 Jun  7 13:44 douban_single_turn.tsv\r\n"
     ]
    }
   ],
   "source": [
    "%ls -lct ~/Studio/dialog_db/chinese_chatbot_corpus-master/clean_chat_corpus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Files():\n",
    "    def __init__(self,):\n",
    "#         self.time = datetime.now()\n",
    "        pass\n",
    "\n",
    "files = Files()\n",
    "\n",
    "path = os.path.abspath(\"../dialog_db/chinese_chatbot_corpus-master/clean_chat_corpus\")\n",
    "file_nms = os.listdir(path)\n",
    "\n",
    "for i in range(len(file_nms)):\n",
    "    setattr(files, file_nms[i].split('.')[0], os.path.join(path, file_nms[i]))\n",
    "    \n",
    "# dirrs(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xiaohuangji.tsv : 454,129\n",
      "tieba.tsv : 2,327,768\n",
      "subtitle.tsv : 2,742,467\n",
      "chatterbot.tsv : 564\n",
      "ptt.tsv : 232,859\n",
      "weibo.tsv : 4,435,959\n",
      "douban_single_turn.tsv : 526,187\n",
      "qingyun.tsv : 105,914\n"
     ]
    }
   ],
   "source": [
    "for name in file_nms:\n",
    "    file = os.path.join(path, name)\n",
    "    with open(file, 'r') as f:\n",
    "        num = len(f.readlines())\n",
    "        print(name,\":\", \"{:,d}\".format(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么庆祝228会被骂可是庆端午不会？\t因为屈原不是台湾人，是楚国人。\n",
      "\n",
      "理论与实务最脱节的系\t哪个系不脱节...你问最不脱节的简单多了...\n",
      "\n",
      "3D小画家有人会画吗？\t3D小当家有人会画吗\n",
      "\n",
      "对天龙人来说宜兰4南部还４东部\t他国事务..\n",
      "\n",
      "机车推出uber或计程机车会怎样\t载到肥宅会很痛苦\n",
      "\n",
      "台中的龙邦世贸有人跳楼?\t曾经当过全台第一高楼，可惜不到一年\n",
      "\n",
      "抽到海陆会被笑娘炮兵吗\t还好啦，海陆下基地常态，下好下满。\n",
      "\n",
      "当初太阳花没有留下垃圾也会被捧？\t哪有，我那时候去也是有垃圾，好像是白什么的\n",
      "\n",
      "欧阳妮妮的男友看到她爸会有感觉吗？\t妮妮的妈妈很爱揍兔子布偶\n",
      "\n",
      "有没有imgurㄉ八卦？\t不要浪费人家空间好吗\n",
      "\n",
      "肥宅初夜可以卖多少？\t肥宅还是去打手枪吧\n",
      "\n",
      "+006是什么地方打来的电话\t你被国际盗懒觉集团盯上了\n",
      "\n",
      "推文速度跟五月天live聊天室滑速哪个快\t聊甜柿华起来\n",
      "\n",
      "转笔兼具速度与华丽的极致是？\t转一万次后说不定你比他们更厉害呢\n",
      "\n",
      "凶的女生484都很胸\t我看都是丑的比较凶\n",
      "\n",
      "猫猫早上是不是都不看人？\t这猫猫好可爱\n",
      "\n",
      "欧金金是哪里的形容词啊？\t日文肉捧的音译啊\n",
      "\n",
      "公车到站系统到底可以多不准\t你什么时候有觉得政府交作业用的会准的错觉？\n",
      "\n",
      "有没有大学排名的八卦？\t高医比台中哪两所高啊?高医不是只有医类分数高吗\n",
      "\n",
      "有妹妹的请进\t我两个妹妹问说你到底在共三小\n",
      "\n",
      "8+9打得赢肥宅吗\t打不赢，会因为重力绕着肥宅做圆周运动\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "with open(files.ptt, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line)\n",
    "        cnt += 1\n",
    "        if cnt > 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = \"../nlp_db/tnews_public\"\n",
    "cfiles = [os.path.join(os.path.abspath(rel_path), os.listdir(rel_path)[i]) for i in range(len(os.listdir(rel_path)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b43ebdeb0ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             raise TypeError('the JSON object must be str, bytes or bytearray, '\n\u001b[0;32m--> 348\u001b[0;31m                             'not {!r}'.format(s.__class__.__name__))\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogatepass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not 'list'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(cfiles[1], 'r') as jf:\n",
    "    json.loads()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
