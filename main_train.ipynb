{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba, json, os, re, sys, time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fields import Field, Parms, Semantic, Vocab, _make_vocab\n",
    "from utils import *\n",
    "\n",
    "from nlp_db import nlp_db\n",
    "\n",
    "from model_class import NLU_Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_hat, y_label):\n",
    "    correct = (torch.argmax(y_hat, dim = 1) == y_label).float()\n",
    "    acc_rate = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc_rate\n",
    "\n",
    "def read_json(file, thresh=20, k=None, func=None):\n",
    "\n",
    "    with open(file, \"r\", encoding='utf-8') as f:\n",
    "        rzlt = []\n",
    "        cnt = 0\n",
    "        for l in f.readlines():\n",
    "\n",
    "            if k != None and func != None:\n",
    "                rzlt.append(func(json.loads(l)[k]))\n",
    "\n",
    "            elif k != None:\n",
    "                rzlt.append(json.loads(l)[k])\n",
    "\n",
    "            else:\n",
    "                rzlt.append(json.loads(l))\n",
    "\n",
    "            if cnt > thresh:\n",
    "                break\n",
    "\n",
    "    return rzlt\n",
    "\n",
    "\n",
    "def json_iter(file, batch_size=1000, k=None, func=None):\n",
    "    with open(file, \"r\", encoding='utf-8') as f:\n",
    "        rzlt = []\n",
    "        for l in f.readlines():\n",
    "            if k != None and func != None:\n",
    "                rzlt.append(func(json.loads(l)[k]))\n",
    "\n",
    "            elif k != None:\n",
    "                rzlt.append(json.loads(l)[k])\n",
    "\n",
    "            else:\n",
    "                rzlt.append(json.loads(l))\n",
    "\n",
    "            if len(rzlt) == batch_size:\n",
    "\n",
    "                yield rzlt\n",
    "                rzlt = []\n",
    "\n",
    "def func_pad(sent):\n",
    "    return [vocab.__getitem__(token) for token in jieba.cut(sent)\n",
    "            ] + [0] * (max_sent_len - len(list(jieba.cut(sent)))) , len(list(jieba.cut(sent)))\n",
    "\n",
    "def restart_iter(batch_size):\n",
    "    x_iter = json_iter(file= trainFile,\n",
    "                       batch_size=batch_size,\n",
    "                       k='sentence',\n",
    "                       func= func_pad\n",
    "                      )\n",
    "\n",
    "    y_iter = json_iter(file=trainFile,\n",
    "                       batch_size = batch_size,\n",
    "                       k='label',\n",
    "                       func=lambda x: label_rdict[x])\n",
    "\n",
    "    return x_iter, y_iter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2124000\r\n",
      "-rw-r--r--  1 root  staff   21695199 Jun  7 13:48 xiaohuangji.tsv\r\n",
      "-rw-r--r--  1 root  staff  465372773 Jun  7 13:48 weibo.tsv\r\n",
      "-rw-r--r--  1 root  staff  298597018 Jun  7 13:46 tieba.tsv\r\n",
      "-rw-r--r--  1 root  staff  151548740 Jun  7 13:46 subtitle.tsv\r\n",
      "-rw-r--r--  1 root  staff    5594328 Jun  7 13:45 qingyun.tsv\r\n",
      "-rw-r--r--  1 root  staff   18202714 Jun  7 13:45 ptt.tsv\r\n",
      "-rw-r--r--  1 root  staff      34249 Jun  7 13:44 chatterbot.tsv\r\n",
      "-rw-r--r--  1 root  staff   85680288 Jun  7 13:44 douban_single_turn.tsv\r\n"
     ]
    }
   ],
   "source": [
    "%ls -lct ~/Studio/dialog_db/chinese_chatbot_corpus-master/clean_chat_corpus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Files():\n",
    "    def __init__(self,):\n",
    "#         self.time = datetime.now()\n",
    "        pass\n",
    "\n",
    "files = Files()\n",
    "\n",
    "path = os.path.abspath(\"../dialog_db/chinese_chatbot_corpus-master/clean_chat_corpus\")\n",
    "file_nms = os.listdir(path)\n",
    "\n",
    "for i in range(len(file_nms)):\n",
    "    setattr(files, file_nms[i].split('.')[0], os.path.join(path, file_nms[i]))\n",
    "    \n",
    "# dirrs(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name in file_nms:\n",
    "    file = os.path.join(path, name)\n",
    "    with open(file, 'r') as f:\n",
    "        num = len(f.readlines())\n",
    "        print(name,\":\", \"{:,d}\".format(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "with open(files.ptt, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line)\n",
    "        cnt += 1\n",
    "        if cnt > 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification data filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/Studio/nlp_db/tnews_public/labels.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/test.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/train.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/vocab.txt',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/.ipynb_checkpoints',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/dev.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_path = \"../nlp_db/tnews_public\"\n",
    "cfiles = [\n",
    "    os.path.join(os.path.abspath(rel_path),\n",
    "                 os.listdir(rel_path)[i])\n",
    "    for i in range(len(os.listdir(rel_path)))\n",
    "]\n",
    "cfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ubuntu/Studio/nlp_db/tnews_public/test.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/train.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/vocab.txt')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile = cfiles[1]\n",
    "trainFile = cfiles[2]\n",
    "vocabFile = cfiles[3]\n",
    "\n",
    "testFile, trainFile, vocabFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cfiles[4]),list(read_json(cfiles[2],100,'sentence', lambda x: list(jieba.cut(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic = Semantic()\n",
    "args = Parms()\n",
    "vocab = Vocab(semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.path = \"../nlp_db/tnews_public\"\n",
    "args.vocab_path = vocabFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.635 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "os.remove(args.vocab_path)\n",
    "if not os.path.isfile(args.vocab_path):\n",
    "    _make_vocab(json_file = trainFile, vocab_path = args.vocab_path, thres=2, level = 'word')\n",
    "    # or just make new vocab\n",
    "    # char level ?\n",
    "    # or chinese word level | with jieba\n",
    "\n",
    "try:\n",
    "    vocab.load(args.vocab_path)\n",
    "except:\n",
    "    print(\"Vocab not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16718, 1061, 0, 3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.size, vocab.__getitem__('ÂêÉ'), vocab.__getitem__('<pad>'), vocab.__getitem__('<unk>'), vocab.__getitem__('<sos>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Process => Model Parms Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_len = max([\n",
    "    len(line) for line in read_json(\n",
    "        trainFile, 60000, k='sentence', func=lambda x: list(jieba.cut(x)))\n",
    "])\n",
    "args.max_sent_len = max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = read_json(cfiles[0], 100, k='label')\n",
    "label_rdict = {l:i for i,l in enumerate(labels)}\n",
    "label_dict = {i:l for i,l in enumerate(labels)}\n",
    "\n",
    "\n",
    "args.class_num = len(labels)\n",
    "\n",
    "args.max_sent_len = max_sent_len\n",
    "args.lstm_step_num = 2\n",
    "args.lstm_hid = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 1000,\n",
       " 'class_num': 15,\n",
       " 'exts': ['.en.atok', '.de.atok'],\n",
       " 'lstm_hid': 64,\n",
       " 'lstm_step_num': 2,\n",
       " 'max_dec_num': 50,\n",
       " 'max_enc_num': 50,\n",
       " 'max_sent_len': 81,\n",
       " 'modes': ['train', 'val', 'test2016'],\n",
       " 'n_sent': 5,\n",
       " 'ndev': 1,\n",
       " 'path': './data/multi30k/',\n",
       " 'vocab_path': '/home/ubuntu/Studio/nlp_db/tnews_public/vocab.txt'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size = 1000\n",
    "dirrm(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Data Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = nn.Embedding(\n",
    "#     vocab.size,\n",
    "#     embedding_dim=128,\n",
    "#     padding_idx=0,\n",
    "# )\n",
    "\n",
    "# x_iter, y_iter = restart_iter(args.batch_size)\n",
    "\n",
    "# cnt = 0\n",
    "# for x, y in zip(x_iter, y_iter):\n",
    "# #     print(list(zip(*[x])))\n",
    "#     batch_x, sent_len = list(zip(*x))\n",
    "#     cnt += 1\n",
    "    \n",
    "#     if cnt > 0:\n",
    "#         break\n",
    "\n",
    "# np.array([np.array(line) for line in batch_x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLU_Classify(nn.Module):\n",
    "    def __init__(self, class_num, vocab, args):\n",
    "        super(NLU_Classify, self).__init__()\n",
    "        self.type = 'classifier'\n",
    "        self.batch_size = args.batch_size\n",
    "        self.serial_len = 2\n",
    "        self.emb = nn.Embedding(vocab.size, embedding_dim=128)\n",
    "        self.lstm = nn.LSTM(128,\n",
    "                            args.lstm_hid,\n",
    "                            args.lstm_step_num,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(64, class_num)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, sent_lengths):\n",
    "        # ? not sure serial_len , batch_size is 100% right\n",
    "        embedded_x = self.emb(x)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded_x,\n",
    "                                                    sent_lengths,\n",
    "                                                    enforce_sorted=False,\n",
    "                                                    batch_first=True)\n",
    "        h0 = torch.randn(self.serial_len, self.batch_size, args.lstm_hid, device = device)\n",
    "        c0 = torch.randn(self.serial_len, self.batch_size, args.lstm_hid, device = device)\n",
    "        x, (hidden, cn) = self.lstm(packed_embedded, (h0, c0))\n",
    "        hidden = hidden[-1,:,:]\n",
    "        output = self.fc(hidden)\n",
    "        output = self.softmax(output)\n",
    "        result = output\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "# Unit test:\n",
    "# x_iter, y_iter = restart_iter(args.batch_size)\n",
    "# cnt = 0\n",
    "# for batch_x, batch_y in zip(x_iter, y_iter):\n",
    "#     batch_x, sent_len = list(zip(*batch_x))\n",
    "#     batch_x = torch.tensor(np.array([np.array(line) for line in batch_x]))\n",
    "#     sent_lengths = torch.tensor(sent_len)\n",
    "#     batch_y = torch.tensor(batch_y)\n",
    "    \n",
    "#     cnt += 1\n",
    "#     if cnt > 0:\n",
    "#         break\n",
    "\n",
    "# sent_lengths.shape, batch_y.shape\n",
    "\n",
    "# y_hat = model(batch_x, sent_lengths)\n",
    "# y_hat.shape\n",
    "\n",
    "# loss_func(y_hat, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLU_Classify(class_num=args.class_num, vocab=vocab, args = args)\n",
    "model.to(device)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tasks\n",
    "\n",
    "# Algorithms\n",
    "\n",
    "# Model State Monitoring and Recording\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - tensorboard with matrics? what are matrics - knowledge base\n",
    "# - cuda device\n",
    "# - save & restore models\n",
    "# - try other models rather than lstm\n",
    "# - train vs. eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "#SummaryWriter encapsulates everything\n",
    "writer = SummaryWriter('runs/exp-2', comment = 'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"manual_trainLog.log\",'r') as f:\n",
    "    l = f.readlines()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb.weight': torch.Size([16718, 128]),\n",
       " 'lstm.weight_ih_l0': torch.Size([256, 128]),\n",
       " 'lstm.weight_hh_l0': torch.Size([256, 64]),\n",
       " 'lstm.bias_ih_l0': torch.Size([256]),\n",
       " 'lstm.bias_hh_l0': torch.Size([256]),\n",
       " 'lstm.weight_ih_l1': torch.Size([256, 64]),\n",
       " 'lstm.weight_hh_l1': torch.Size([256, 64]),\n",
       " 'lstm.bias_ih_l1': torch.Size([256]),\n",
       " 'lstm.bias_hh_l1': torch.Size([256]),\n",
       " 'fc.weight': torch.Size([15, 64]),\n",
       " 'fc.bias': torch.Size([15])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Trained Parameters\n",
    "# model.state_dict()    # is a ordered dict\n",
    "{k: model.state_dict()[k].shape for k in model.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./model_stores'):\n",
    "    os.mkdir('./model_stores')\n",
    "\n",
    "args.model_path = './model_stores/model.pth'\n",
    "\n",
    "first_train = False\n",
    "\n",
    "# Load:\n",
    "if os.path.isfile(args.model_path) and first_train == False:\n",
    "    model.load_state_dict(torch.load(args.model_path))\n",
    "    model.train()    # set model to train mode\n",
    "#     model.eval()    # set model to train mode\n",
    "\n",
    "# for epoch in range(100):\n",
    "last_epoch = 1\n",
    "epoch = last_epoch\n",
    "if not \"acc_rates\" in locals():\n",
    "    acc_rates = [0] * 8\n",
    "# while True:\n",
    "\n",
    "while np.array(acc_rates).sum() / len(acc_rates) < 0.8:\n",
    "    epoch += 1\n",
    "    x_iter, y_iter = restart_iter(args.batch_size)\n",
    "\n",
    "    ep_cnt = 0\n",
    "    acc_loss = []\n",
    "    acc_rates = []\n",
    "    for batch_x, batch_y in zip(x_iter, y_iter):\n",
    "        batch_x, sent_lengths = list(zip(*batch_x))\n",
    "\n",
    "        batch_x = torch.tensor(np.array([np.array(line) for line in batch_x]))\n",
    "        sent_lengths = torch.tensor(sent_lengths)\n",
    "        batch_y = torch.tensor(batch_y)\n",
    "\n",
    "        batch_x = batch_x.to(device)\n",
    "        sent_lengths = sent_lengths.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(batch_x, sent_lengths)\n",
    "        loss = loss_func(y_hat, batch_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_rate = acc(y_hat, batch_y)\n",
    "\n",
    "        ep_cnt += 1\n",
    "        acc_loss.append(loss)\n",
    "        acc_rates.append(acc_rate)\n",
    "        if ep_cnt % 20 == 0:\n",
    "            last_loss, last_avgac = np.array(acc_loss).sum() / len(\n",
    "                acc_loss), np.array(acc_rates).sum() / len(acc_rates)\n",
    "            print(epoch, \"loss: \", last_loss.data, \"Acc: \", last_avgac)\n",
    "\n",
    "            writer.add_scalar('loss:', last_loss,\n",
    "                              epoch + 0.32 * (ep_cnt % 20))\n",
    "            writer.add_scalar('avg acc:', last_avgac,\n",
    "                              epoch + 0.32 * (ep_cnt % 20))\n",
    "\n",
    "            acc_loss = []\n",
    "            acc_rates = []\n",
    "\n",
    "            # Save:\n",
    "            torch.save(model.state_dict(), f=args.model_path)\n",
    "#             os.system('clear')\n",
    "\n",
    "\n",
    "            # Eval\n",
    "            model.eval()\n",
    "            \n",
    "\n",
    "#     loss.backward(retain_graph=True)\n",
    "\n",
    "        last_epoch = epoch\n",
    "\n",
    "    with open('./manuLog_lstm1.log','a') as af:\n",
    "        af.write(\"epoch: {}, loss: {},train_avg_acc: {}\".format(last_epoch, last_loss, last_avgac),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def predict_to_sent(result):\n",
    "#     return [''.join([vocab.vocab_rdict[tkid.tolist()] for tkid in line]) for line in result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
