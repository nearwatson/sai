{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba, json, os, re, sys, time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fields import Field, Parms, Semantic, Vocab, _make_vocab\n",
    "from utils import *\n",
    "\n",
    "from nlp_db import nlp_db\n",
    "\n",
    "from model_class import NLU_Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file, thresh=20, k=None, func=None):\n",
    "\n",
    "    with open(file, \"r\", encoding='utf-8') as f:\n",
    "        rzlt = []\n",
    "        cnt = 0\n",
    "        for l in f.readlines():\n",
    "\n",
    "            if k != None and func != None:\n",
    "                rzlt.append(func(json.loads(l)[k]))\n",
    "\n",
    "            elif k != None:\n",
    "                rzlt.append(json.loads(l)[k])\n",
    "\n",
    "            else:\n",
    "                rzlt.append(json.loads(l))\n",
    "\n",
    "            if cnt > thresh:\n",
    "                break\n",
    "\n",
    "    return rzlt\n",
    "\n",
    "\n",
    "def json_iter(file, batch_size=1000, k=None, func=None):\n",
    "    with open(file, \"r\", encoding='utf-8') as f:\n",
    "        rzlt = []\n",
    "        for l in f.readlines():\n",
    "            if k != None and func != None:\n",
    "                rzlt.append(func(json.loads(l)[k]))\n",
    "\n",
    "            elif k != None:\n",
    "                rzlt.append(json.loads(l)[k])\n",
    "\n",
    "            else:\n",
    "                rzlt.append(json.loads(l))\n",
    "\n",
    "            if len(rzlt) == batch_size:\n",
    "\n",
    "                yield rzlt\n",
    "                rzlt = []\n",
    "\n",
    "def func_pad(sent):\n",
    "    return [vocab.__getitem__(token) for token in jieba.cut(sent)\n",
    "            ] + [0] * (max_sent_len - len(list(jieba.cut(sent)))) , len(list(jieba.cut(sent)))\n",
    "\n",
    "def restart_iter(batch_size):\n",
    "    x_iter = json_iter(file= trainFile,\n",
    "                       batch_size=batch_size,\n",
    "                       k='sentence',\n",
    "                       func= func_pad\n",
    "                      )\n",
    "\n",
    "    y_iter = json_iter(file=trainFile,\n",
    "                       batch_size = batch_size,\n",
    "                       k='label',\n",
    "                       func=lambda x: label_rdict[x])\n",
    "\n",
    "    return x_iter, y_iter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2124000\r\n",
      "-rw-r--r--  1 root  staff   21695199 Jun  7 13:48 xiaohuangji.tsv\r\n",
      "-rw-r--r--  1 root  staff  465372773 Jun  7 13:48 weibo.tsv\r\n",
      "-rw-r--r--  1 root  staff  298597018 Jun  7 13:46 tieba.tsv\r\n",
      "-rw-r--r--  1 root  staff  151548740 Jun  7 13:46 subtitle.tsv\r\n",
      "-rw-r--r--  1 root  staff    5594328 Jun  7 13:45 qingyun.tsv\r\n",
      "-rw-r--r--  1 root  staff   18202714 Jun  7 13:45 ptt.tsv\r\n",
      "-rw-r--r--  1 root  staff      34249 Jun  7 13:44 chatterbot.tsv\r\n",
      "-rw-r--r--  1 root  staff   85680288 Jun  7 13:44 douban_single_turn.tsv\r\n"
     ]
    }
   ],
   "source": [
    "%ls -lct ~/Studio/dialog_db/chinese_chatbot_corpus-master/clean_chat_corpus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Files():\n",
    "    def __init__(self,):\n",
    "#         self.time = datetime.now()\n",
    "        pass\n",
    "\n",
    "files = Files()\n",
    "\n",
    "path = os.path.abspath(\"../dialog_db/chinese_chatbot_corpus-master/clean_chat_corpus\")\n",
    "file_nms = os.listdir(path)\n",
    "\n",
    "for i in range(len(file_nms)):\n",
    "    setattr(files, file_nms[i].split('.')[0], os.path.join(path, file_nms[i]))\n",
    "    \n",
    "# dirrs(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name in file_nms:\n",
    "    file = os.path.join(path, name)\n",
    "    with open(file, 'r') as f:\n",
    "        num = len(f.readlines())\n",
    "        print(name,\":\", \"{:,d}\".format(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "with open(files.ptt, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line)\n",
    "        cnt += 1\n",
    "        if cnt > 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification data filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/Studio/nlp_db/tnews_public/labels.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/test.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/train.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/vocab.txt',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/.ipynb_checkpoints',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/dev.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_path = \"../nlp_db/tnews_public\"\n",
    "cfiles = [\n",
    "    os.path.join(os.path.abspath(rel_path),\n",
    "                 os.listdir(rel_path)[i])\n",
    "    for i in range(len(os.listdir(rel_path)))\n",
    "]\n",
    "cfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ubuntu/Studio/nlp_db/tnews_public/train.json',\n",
       " '/home/ubuntu/Studio/nlp_db/tnews_public/vocab.txt')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFile = cfiles[2]\n",
    "vocabFile = cfiles[3]\n",
    "\n",
    "trainFile, vocabFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cfiles[4]),list(read_json(cfiles[2],100,'sentence', lambda x: list(jieba.cut(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic = Semantic()\n",
    "args = Parms()\n",
    "vocab = Vocab(semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.path = \"../nlp_db/tnews_public\"\n",
    "args.vocab_path = \"../nlp_db/tnews_public/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.654 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "os.remove(args.vocab_path)\n",
    "if not os.path.isfile(args.vocab_path):\n",
    "    _make_vocab(json_file = trainFile, vocab_path = args.vocab_path, thres=2, level = 'word')\n",
    "    # or just make new vocab\n",
    "    # char level ?\n",
    "    # or chinese word level | with jieba\n",
    "\n",
    "try:\n",
    "    vocab.load(args.vocab_path)\n",
    "except:\n",
    "    print(\"Vocab not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16718, 1061, 0, 3, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.size, vocab.__getitem__('ÂêÉ'), vocab.__getitem__('<pad>'), vocab.__getitem__('<unk>'), vocab.__getitem__('<sos>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Process => Model Parms Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_len = max([\n",
    "    len(line) for line in read_json(\n",
    "        trainFile, 60000, k='sentence', func=lambda x: list(jieba.cut(x)))\n",
    "])\n",
    "args.max_sent_len = max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = read_json(cfiles[0], 100, k='label')\n",
    "label_rdict = {l:i for i,l in enumerate(labels)}\n",
    "label_dict = {i:l for i,l in enumerate(labels)}\n",
    "\n",
    "\n",
    "args.class_num = len(labels)\n",
    "\n",
    "args.max_sent_len = max_sent_len\n",
    "args.lstm_step_num = 2\n",
    "args.lstm_hid = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 1000,\n",
       " 'class_num': 15,\n",
       " 'exts': ['.en.atok', '.de.atok'],\n",
       " 'lstm_hid': 64,\n",
       " 'lstm_step_num': 2,\n",
       " 'max_dec_num': 50,\n",
       " 'max_enc_num': 50,\n",
       " 'max_sent_len': 81,\n",
       " 'modes': ['train', 'val', 'test2016'],\n",
       " 'n_sent': 5,\n",
       " 'ndev': 1,\n",
       " 'path': './data/multi30k/',\n",
       " 'vocab_path': '../nlp_db/tnews_public/vocab.txt'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size = 1000\n",
    "dirrm(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Data Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = nn.Embedding(\n",
    "#     vocab.size,\n",
    "#     embedding_dim=128,\n",
    "#     padding_idx=0,\n",
    "# )\n",
    "\n",
    "# x_iter, y_iter = restart_iter(args.batch_size)\n",
    "\n",
    "# cnt = 0\n",
    "# for x, y in zip(x_iter, y_iter):\n",
    "# #     print(list(zip(*[x])))\n",
    "#     batch_x, sent_len = list(zip(*x))\n",
    "#     cnt += 1\n",
    "    \n",
    "#     if cnt > 0:\n",
    "#         break\n",
    "\n",
    "# np.array([np.array(line) for line in batch_x])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# batch_x, sent_len = list(zip(*next(x_iter)))\n",
    "# batch_x = torch.tensor(np.array([np.array(line) for line in batch_x]))\n",
    "# sent_lengths = torch.tensor(sent_len)\n",
    "\n",
    "# embedded_x = emb(batch_x)\n",
    "\n",
    "# packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded_x,\n",
    "#                                                     sent_lengths,\n",
    "#                                                     enforce_sorted=False,\n",
    "#                                                     batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NLU_Classify(nn.Module):\n",
    "#     def __init__(self, class_num, vocab):\n",
    "#         super(NLU_Classify, self).__init__()\n",
    "#         self.type = 'classifier'\n",
    "#         self.batch_size = 1000\n",
    "#         self.serial_len = 2\n",
    "#         self.emb = nn.Embedding(vocab.size, embedding_dim=128)\n",
    "#         self.lstm = nn.LSTM(128,\n",
    "#                             args.lstm_hid,\n",
    "#                             args.lstm_step_num,\n",
    "#                             batch_first=True)\n",
    "#         self.fc = nn.Linear(64, class_num)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "#     def forward(self, x, sent_lengths):\n",
    "#         # ? not sure serial_len , batch_size is 100% right\n",
    "#         embedded_x = self.emb(x)\n",
    "#         packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded_x,\n",
    "#                                                     sent_lengths,\n",
    "#                                                     enforce_sorted=False,\n",
    "#                                                     batch_first=True)\n",
    "#         h0 = torch.randn(self.serial_len, self.batch_size, args.lstm_hid)\n",
    "#         c0 = torch.randn(self.serial_len, self.batch_size, args.lstm_hid)\n",
    "#         x, (hidden, cn) = self.lstm(packed_embedded, (h0, c0))\n",
    "#         hidden = hidden[-1,:,:]\n",
    "#         x = self.fc(hidden)\n",
    "# #         x = x[:, -1, :]\n",
    "#         x = self.softmax(x)\n",
    "#         result = x\n",
    "\n",
    "#         return result\n",
    "\n",
    "# fw = NLU_Classify(args.class_num, vocab)\n",
    "# yhat = fw(batch_x, sent_lengths)\n",
    "# batch_x.shape, yhat.shape, yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLU_Classify(nn.Module):\n",
    "    def __init__(self, class_num, vocab, args):\n",
    "        super(NLU_Classify, self).__init__()\n",
    "        self.type = 'classifier'\n",
    "        self.batch_size = args.batch_size\n",
    "        self.serial_len = 2\n",
    "        self.emb = nn.Embedding(vocab.size, embedding_dim=128)\n",
    "        self.lstm = nn.LSTM(128,\n",
    "                            args.lstm_hid,\n",
    "                            args.lstm_step_num,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(64, class_num)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, sent_lengths):\n",
    "        # ? not sure serial_len , batch_size is 100% right\n",
    "        embedded_x = self.emb(x)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded_x,\n",
    "                                                    sent_lengths,\n",
    "                                                    enforce_sorted=False,\n",
    "                                                    batch_first=True)\n",
    "        h0 = torch.randn(self.serial_len, self.batch_size, args.lstm_hid, device = device)\n",
    "        c0 = torch.randn(self.serial_len, self.batch_size, args.lstm_hid, device = device)\n",
    "        x, (hidden, cn) = self.lstm(packed_embedded, (h0, c0))\n",
    "        hidden = hidden[-1,:,:]\n",
    "        output = self.fc(hidden)\n",
    "#         x = x[:, -1, :]\n",
    "        output = self.softmax(output)\n",
    "        result = output\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "# Unit test:\n",
    "# x_iter, y_iter = restart_iter(args.batch_size)\n",
    "# cnt = 0\n",
    "# for batch_x, batch_y in zip(x_iter, y_iter):\n",
    "#     batch_x, sent_len = list(zip(*batch_x))\n",
    "#     batch_x = torch.tensor(np.array([np.array(line) for line in batch_x]))\n",
    "#     sent_lengths = torch.tensor(sent_len)\n",
    "#     batch_y = torch.tensor(batch_y)\n",
    "    \n",
    "#     cnt += 1\n",
    "#     if cnt > 0:\n",
    "#         break\n",
    "\n",
    "# sent_lengths.shape, batch_y.shape\n",
    "\n",
    "# y_hat = model(batch_x, sent_lengths)\n",
    "# y_hat.shape\n",
    "\n",
    "# loss_func(y_hat, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLU_Classify(\n",
      "  (emb): Embedding(16718, 128)\n",
      "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=15, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NLU_Classify(\n",
       "  (emb): Embedding(16718, 128)\n",
       "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=15, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NLU_Classify(class_num=args.class_num, vocab=vocab, args = args)\n",
    "print(model)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_x = batch_x.to(device)\n",
    "# sent_lengths = sent_lengths.to(device)\n",
    "\n",
    "# batch_x, sent_lengths\n",
    "\n",
    "# model(batch_x, sent_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_hat, y_label):\n",
    "    correct = (torch.argmax(y_hat, dim = 1) == y_label).float()\n",
    "    acc_rate = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - tensorboard with matrics\n",
    "# - cuda device\n",
    "# - save & restore models\n",
    "# - try other models rather than lstm\n",
    "# - train vs. eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "#SummaryWriter encapsulates everything\n",
    "writer = SummaryWriter('runs/exp-1', comment = 'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoach = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./model_stores'):\n",
    "    os.mkdir('./model_stores')\n",
    "\n",
    "args.model_path = './model_stores/model.pth'\n",
    "\n",
    "first_train = False\n",
    "\n",
    "# Load:\n",
    "if os.path.isfile(args.model_path) and first_train == False:\n",
    "    model.load_state_dict(torch.load(args.model_path))\n",
    "    model.train()    # set model to train mode\n",
    "#     model.eval()    # set model to train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801 loss:  tensor(2.4511, device='cuda:0') Acc:  tensor(0.3647, device='cuda:0')\n",
      "801 loss:  tensor(2.4411, device='cuda:0') Acc:  tensor(0.3755, device='cuda:0')\n",
      "802 loss:  tensor(2.4362, device='cuda:0') Acc:  tensor(0.3821, device='cuda:0')\n",
      "802 loss:  tensor(2.4336, device='cuda:0') Acc:  tensor(0.3846, device='cuda:0')\n",
      "803 loss:  tensor(2.4361, device='cuda:0') Acc:  tensor(0.3824, device='cuda:0')\n",
      "803 loss:  tensor(2.4326, device='cuda:0') Acc:  tensor(0.3851, device='cuda:0')\n",
      "804 loss:  tensor(2.4342, device='cuda:0') Acc:  tensor(0.3842, device='cuda:0')\n",
      "804 loss:  tensor(2.4354, device='cuda:0') Acc:  tensor(0.3825, device='cuda:0')\n",
      "805 loss:  tensor(2.4346, device='cuda:0') Acc:  tensor(0.3839, device='cuda:0')\n",
      "805 loss:  tensor(2.4355, device='cuda:0') Acc:  tensor(0.3815, device='cuda:0')\n",
      "806 loss:  tensor(2.4340, device='cuda:0') Acc:  tensor(0.3842, device='cuda:0')\n",
      "806 loss:  tensor(2.4363, device='cuda:0') Acc:  tensor(0.3819, device='cuda:0')\n",
      "807 loss:  tensor(2.4342, device='cuda:0') Acc:  tensor(0.3837, device='cuda:0')\n",
      "807 loss:  tensor(2.4355, device='cuda:0') Acc:  tensor(0.3825, device='cuda:0')\n",
      "808 loss:  tensor(2.4319, device='cuda:0') Acc:  tensor(0.3862, device='cuda:0')\n",
      "808 loss:  tensor(2.4376, device='cuda:0') Acc:  tensor(0.3809, device='cuda:0')\n",
      "809 loss:  tensor(2.4325, device='cuda:0') Acc:  tensor(0.3861, device='cuda:0')\n",
      "809 loss:  tensor(2.4354, device='cuda:0') Acc:  tensor(0.3828, device='cuda:0')\n",
      "810 loss:  tensor(2.4321, device='cuda:0') Acc:  tensor(0.3864, device='cuda:0')\n",
      "810 loss:  tensor(2.4375, device='cuda:0') Acc:  tensor(0.3803, device='cuda:0')\n",
      "811 loss:  tensor(2.4324, device='cuda:0') Acc:  tensor(0.3857, device='cuda:0')\n",
      "811 loss:  tensor(2.4354, device='cuda:0') Acc:  tensor(0.3827, device='cuda:0')\n",
      "812 loss:  tensor(2.4343, device='cuda:0') Acc:  tensor(0.3844, device='cuda:0')\n",
      "812 loss:  tensor(2.4344, device='cuda:0') Acc:  tensor(0.3844, device='cuda:0')\n",
      "813 loss:  tensor(2.4323, device='cuda:0') Acc:  tensor(0.3860, device='cuda:0')\n",
      "813 loss:  tensor(2.4359, device='cuda:0') Acc:  tensor(0.3822, device='cuda:0')\n",
      "814 loss:  tensor(2.4350, device='cuda:0') Acc:  tensor(0.3835, device='cuda:0')\n",
      "814 loss:  tensor(2.4337, device='cuda:0') Acc:  tensor(0.3842, device='cuda:0')\n",
      "815 loss:  tensor(2.4359, device='cuda:0') Acc:  tensor(0.3817, device='cuda:0')\n",
      "815 loss:  tensor(2.4340, device='cuda:0') Acc:  tensor(0.3836, device='cuda:0')\n",
      "816 loss:  tensor(2.4390, device='cuda:0') Acc:  tensor(0.3792, device='cuda:0')\n",
      "816 loss:  tensor(2.4310, device='cuda:0') Acc:  tensor(0.3861, device='cuda:0')\n",
      "817 loss:  tensor(2.4402, device='cuda:0') Acc:  tensor(0.3783, device='cuda:0')\n",
      "817 loss:  tensor(2.4336, device='cuda:0') Acc:  tensor(0.3844, device='cuda:0')\n",
      "818 loss:  tensor(2.4429, device='cuda:0') Acc:  tensor(0.3749, device='cuda:0')\n",
      "818 loss:  tensor(2.4395, device='cuda:0') Acc:  tensor(0.3784, device='cuda:0')\n",
      "819 loss:  tensor(2.4416, device='cuda:0') Acc:  tensor(0.3757, device='cuda:0')\n",
      "819 loss:  tensor(2.4402, device='cuda:0') Acc:  tensor(0.3780, device='cuda:0')\n",
      "820 loss:  tensor(2.4409, device='cuda:0') Acc:  tensor(0.3767, device='cuda:0')\n",
      "820 loss:  tensor(2.4440, device='cuda:0') Acc:  tensor(0.3745, device='cuda:0')\n",
      "821 loss:  tensor(2.4399, device='cuda:0') Acc:  tensor(0.3779, device='cuda:0')\n",
      "821 loss:  tensor(2.4448, device='cuda:0') Acc:  tensor(0.3735, device='cuda:0')\n",
      "822 loss:  tensor(2.4422, device='cuda:0') Acc:  tensor(0.3755, device='cuda:0')\n",
      "822 loss:  tensor(2.4511, device='cuda:0') Acc:  tensor(0.3671, device='cuda:0')\n",
      "823 loss:  tensor(2.4448, device='cuda:0') Acc:  tensor(0.3726, device='cuda:0')\n",
      "823 loss:  tensor(2.4495, device='cuda:0') Acc:  tensor(0.3678, device='cuda:0')\n",
      "824 loss:  tensor(2.4458, device='cuda:0') Acc:  tensor(0.3717, device='cuda:0')\n",
      "824 loss:  tensor(2.4519, device='cuda:0') Acc:  tensor(0.3654, device='cuda:0')\n",
      "825 loss:  tensor(2.4530, device='cuda:0') Acc:  tensor(0.3637, device='cuda:0')\n",
      "825 loss:  tensor(2.4508, device='cuda:0') Acc:  tensor(0.3668, device='cuda:0')\n",
      "826 loss:  tensor(2.4522, device='cuda:0') Acc:  tensor(0.3645, device='cuda:0')\n",
      "826 loss:  tensor(2.4466, device='cuda:0') Acc:  tensor(0.3694, device='cuda:0')\n",
      "827 loss:  tensor(2.4476, device='cuda:0') Acc:  tensor(0.3691, device='cuda:0')\n",
      "827 loss:  tensor(2.4406, device='cuda:0') Acc:  tensor(0.3758, device='cuda:0')\n",
      "828 loss:  tensor(2.4415, device='cuda:0') Acc:  tensor(0.3740, device='cuda:0')\n",
      "828 loss:  tensor(2.4393, device='cuda:0') Acc:  tensor(0.3777, device='cuda:0')\n",
      "829 loss:  tensor(2.4393, device='cuda:0') Acc:  tensor(0.3771, device='cuda:0')\n",
      "829 loss:  tensor(2.4349, device='cuda:0') Acc:  tensor(0.3819, device='cuda:0')\n",
      "830 loss:  tensor(2.4356, device='cuda:0') Acc:  tensor(0.3813, device='cuda:0')\n",
      "830 loss:  tensor(2.4326, device='cuda:0') Acc:  tensor(0.3845, device='cuda:0')\n",
      "831 loss:  tensor(2.4335, device='cuda:0') Acc:  tensor(0.3833, device='cuda:0')\n",
      "831 loss:  tensor(2.4321, device='cuda:0') Acc:  tensor(0.3850, device='cuda:0')\n",
      "832 loss:  tensor(2.4316, device='cuda:0') Acc:  tensor(0.3858, device='cuda:0')\n",
      "832 loss:  tensor(2.4294, device='cuda:0') Acc:  tensor(0.3880, device='cuda:0')\n",
      "833 loss:  tensor(2.4303, device='cuda:0') Acc:  tensor(0.3869, device='cuda:0')\n",
      "833 loss:  tensor(2.4285, device='cuda:0') Acc:  tensor(0.3886, device='cuda:0')\n",
      "834 loss:  tensor(2.4290, device='cuda:0') Acc:  tensor(0.3880, device='cuda:0')\n",
      "834 loss:  tensor(2.4278, device='cuda:0') Acc:  tensor(0.3891, device='cuda:0')\n",
      "835 loss:  tensor(2.4289, device='cuda:0') Acc:  tensor(0.3879, device='cuda:0')\n",
      "835 loss:  tensor(2.4278, device='cuda:0') Acc:  tensor(0.3889, device='cuda:0')\n",
      "836 loss:  tensor(2.4283, device='cuda:0') Acc:  tensor(0.3892, device='cuda:0')\n",
      "836 loss:  tensor(2.4260, device='cuda:0') Acc:  tensor(0.3908, device='cuda:0')\n",
      "837 loss:  tensor(2.4278, device='cuda:0') Acc:  tensor(0.3890, device='cuda:0')\n",
      "837 loss:  tensor(2.4262, device='cuda:0') Acc:  tensor(0.3902, device='cuda:0')\n",
      "838 loss:  tensor(2.4261, device='cuda:0') Acc:  tensor(0.3907, device='cuda:0')\n",
      "838 loss:  tensor(2.4258, device='cuda:0') Acc:  tensor(0.3906, device='cuda:0')\n",
      "839 loss:  tensor(2.4258, device='cuda:0') Acc:  tensor(0.3910, device='cuda:0')\n",
      "839 loss:  tensor(2.4251, device='cuda:0') Acc:  tensor(0.3912, device='cuda:0')\n",
      "840 loss:  tensor(2.4255, device='cuda:0') Acc:  tensor(0.3912, device='cuda:0')\n",
      "840 loss:  tensor(2.4236, device='cuda:0') Acc:  tensor(0.3926, device='cuda:0')\n",
      "841 loss:  tensor(2.4263, device='cuda:0') Acc:  tensor(0.3903, device='cuda:0')\n",
      "841 loss:  tensor(2.4237, device='cuda:0') Acc:  tensor(0.3934, device='cuda:0')\n",
      "842 loss:  tensor(2.4245, device='cuda:0') Acc:  tensor(0.3925, device='cuda:0')\n",
      "842 loss:  tensor(2.4235, device='cuda:0') Acc:  tensor(0.3933, device='cuda:0')\n",
      "843 loss:  tensor(2.4244, device='cuda:0') Acc:  tensor(0.3918, device='cuda:0')\n",
      "843 loss:  tensor(2.4228, device='cuda:0') Acc:  tensor(0.3934, device='cuda:0')\n",
      "844 loss:  tensor(2.4242, device='cuda:0') Acc:  tensor(0.3923, device='cuda:0')\n",
      "844 loss:  tensor(2.4224, device='cuda:0') Acc:  tensor(0.3942, device='cuda:0')\n",
      "845 loss:  tensor(2.4241, device='cuda:0') Acc:  tensor(0.3925, device='cuda:0')\n",
      "845 loss:  tensor(2.4218, device='cuda:0') Acc:  tensor(0.3951, device='cuda:0')\n",
      "846 loss:  tensor(2.4232, device='cuda:0') Acc:  tensor(0.3933, device='cuda:0')\n",
      "846 loss:  tensor(2.4217, device='cuda:0') Acc:  tensor(0.3946, device='cuda:0')\n",
      "847 loss:  tensor(2.4226, device='cuda:0') Acc:  tensor(0.3938, device='cuda:0')\n",
      "847 loss:  tensor(2.4208, device='cuda:0') Acc:  tensor(0.3962, device='cuda:0')\n",
      "848 loss:  tensor(2.4222, device='cuda:0') Acc:  tensor(0.3940, device='cuda:0')\n",
      "848 loss:  tensor(2.4208, device='cuda:0') Acc:  tensor(0.3962, device='cuda:0')\n",
      "849 loss:  tensor(2.4220, device='cuda:0') Acc:  tensor(0.3939, device='cuda:0')\n",
      "849 loss:  tensor(2.4197, device='cuda:0') Acc:  tensor(0.3967, device='cuda:0')\n",
      "850 loss:  tensor(2.4221, device='cuda:0') Acc:  tensor(0.3942, device='cuda:0')\n",
      "850 loss:  tensor(2.4198, device='cuda:0') Acc:  tensor(0.3975, device='cuda:0')\n",
      "851 loss:  tensor(2.4217, device='cuda:0') Acc:  tensor(0.3946, device='cuda:0')\n",
      "851 loss:  tensor(2.4196, device='cuda:0') Acc:  tensor(0.3970, device='cuda:0')\n",
      "852 loss:  tensor(2.4210, device='cuda:0') Acc:  tensor(0.3955, device='cuda:0')\n",
      "852 loss:  tensor(2.4196, device='cuda:0') Acc:  tensor(0.3972, device='cuda:0')\n",
      "853 loss:  tensor(2.4218, device='cuda:0') Acc:  tensor(0.3941, device='cuda:0')\n",
      "853 loss:  tensor(2.4193, device='cuda:0') Acc:  tensor(0.3967, device='cuda:0')\n",
      "854 loss:  tensor(2.4206, device='cuda:0') Acc:  tensor(0.3955, device='cuda:0')\n",
      "854 loss:  tensor(2.4190, device='cuda:0') Acc:  tensor(0.3972, device='cuda:0')\n",
      "855 loss:  tensor(2.4200, device='cuda:0') Acc:  tensor(0.3964, device='cuda:0')\n",
      "855 loss:  tensor(2.4192, device='cuda:0') Acc:  tensor(0.3970, device='cuda:0')\n",
      "856 loss:  tensor(2.4206, device='cuda:0') Acc:  tensor(0.3957, device='cuda:0')\n",
      "856 loss:  tensor(2.4185, device='cuda:0') Acc:  tensor(0.3977, device='cuda:0')\n",
      "857 loss:  tensor(2.4201, device='cuda:0') Acc:  tensor(0.3968, device='cuda:0')\n",
      "857 loss:  tensor(2.4186, device='cuda:0') Acc:  tensor(0.3980, device='cuda:0')\n",
      "858 loss:  tensor(2.4206, device='cuda:0') Acc:  tensor(0.3958, device='cuda:0')\n",
      "858 loss:  tensor(2.4179, device='cuda:0') Acc:  tensor(0.3989, device='cuda:0')\n",
      "859 loss:  tensor(2.4205, device='cuda:0') Acc:  tensor(0.3958, device='cuda:0')\n",
      "859 loss:  tensor(2.4185, device='cuda:0') Acc:  tensor(0.3975, device='cuda:0')\n",
      "860 loss:  tensor(2.4200, device='cuda:0') Acc:  tensor(0.3963, device='cuda:0')\n",
      "860 loss:  tensor(2.4176, device='cuda:0') Acc:  tensor(0.3989, device='cuda:0')\n",
      "861 loss:  tensor(2.4200, device='cuda:0') Acc:  tensor(0.3963, device='cuda:0')\n",
      "861 loss:  tensor(2.4185, device='cuda:0') Acc:  tensor(0.3977, device='cuda:0')\n",
      "862 loss:  tensor(2.4197, device='cuda:0') Acc:  tensor(0.3966, device='cuda:0')\n",
      "862 loss:  tensor(2.4177, device='cuda:0') Acc:  tensor(0.3987, device='cuda:0')\n",
      "863 loss:  tensor(2.4192, device='cuda:0') Acc:  tensor(0.3968, device='cuda:0')\n",
      "863 loss:  tensor(2.4179, device='cuda:0') Acc:  tensor(0.3985, device='cuda:0')\n",
      "864 loss:  tensor(2.4189, device='cuda:0') Acc:  tensor(0.3978, device='cuda:0')\n",
      "864 loss:  tensor(2.4171, device='cuda:0') Acc:  tensor(0.3998, device='cuda:0')\n",
      "865 loss:  tensor(2.4190, device='cuda:0') Acc:  tensor(0.3973, device='cuda:0')\n",
      "865 loss:  tensor(2.4170, device='cuda:0') Acc:  tensor(0.3994, device='cuda:0')\n",
      "866 loss:  tensor(2.4193, device='cuda:0') Acc:  tensor(0.3969, device='cuda:0')\n",
      "866 loss:  tensor(2.4170, device='cuda:0') Acc:  tensor(0.3996, device='cuda:0')\n",
      "867 loss:  tensor(2.4188, device='cuda:0') Acc:  tensor(0.3974, device='cuda:0')\n",
      "867 loss:  tensor(2.4170, device='cuda:0') Acc:  tensor(0.3995, device='cuda:0')\n",
      "868 loss:  tensor(2.4179, device='cuda:0') Acc:  tensor(0.3981, device='cuda:0')\n",
      "868 loss:  tensor(2.4172, device='cuda:0') Acc:  tensor(0.3998, device='cuda:0')\n",
      "869 loss:  tensor(2.4184, device='cuda:0') Acc:  tensor(0.3980, device='cuda:0')\n",
      "869 loss:  tensor(2.4172, device='cuda:0') Acc:  tensor(0.3995, device='cuda:0')\n",
      "870 loss:  tensor(2.4184, device='cuda:0') Acc:  tensor(0.3976, device='cuda:0')\n",
      "870 loss:  tensor(2.4167, device='cuda:0') Acc:  tensor(0.3996, device='cuda:0')\n",
      "871 loss:  tensor(2.4178, device='cuda:0') Acc:  tensor(0.3980, device='cuda:0')\n",
      "871 loss:  tensor(2.4160, device='cuda:0') Acc:  tensor(0.3997, device='cuda:0')\n",
      "872 loss:  tensor(2.4179, device='cuda:0') Acc:  tensor(0.3981, device='cuda:0')\n",
      "872 loss:  tensor(2.4163, device='cuda:0') Acc:  tensor(0.4000, device='cuda:0')\n",
      "873 loss:  tensor(2.4179, device='cuda:0') Acc:  tensor(0.3982, device='cuda:0')\n",
      "873 loss:  tensor(2.4164, device='cuda:0') Acc:  tensor(0.3998, device='cuda:0')\n",
      "874 loss:  tensor(2.4188, device='cuda:0') Acc:  tensor(0.3974, device='cuda:0')\n",
      "874 loss:  tensor(2.4154, device='cuda:0') Acc:  tensor(0.4008, device='cuda:0')\n",
      "875 loss:  tensor(2.4179, device='cuda:0') Acc:  tensor(0.3989, device='cuda:0')\n",
      "875 loss:  tensor(2.4155, device='cuda:0') Acc:  tensor(0.4011, device='cuda:0')\n",
      "876 loss:  tensor(2.4177, device='cuda:0') Acc:  tensor(0.3980, device='cuda:0')\n",
      "876 loss:  tensor(2.4155, device='cuda:0') Acc:  tensor(0.4005, device='cuda:0')\n",
      "877 loss:  tensor(2.4171, device='cuda:0') Acc:  tensor(0.3992, device='cuda:0')\n",
      "877 loss:  tensor(2.4154, device='cuda:0') Acc:  tensor(0.4010, device='cuda:0')\n",
      "878 loss:  tensor(2.4174, device='cuda:0') Acc:  tensor(0.3982, device='cuda:0')\n",
      "878 loss:  tensor(2.4150, device='cuda:0') Acc:  tensor(0.4009, device='cuda:0')\n",
      "879 loss:  tensor(2.4175, device='cuda:0') Acc:  tensor(0.3987, device='cuda:0')\n",
      "879 loss:  tensor(2.4156, device='cuda:0') Acc:  tensor(0.4008, device='cuda:0')\n",
      "880 loss:  tensor(2.4170, device='cuda:0') Acc:  tensor(0.3992, device='cuda:0')\n",
      "880 loss:  tensor(2.4156, device='cuda:0') Acc:  tensor(0.4007, device='cuda:0')\n",
      "881 loss:  tensor(2.4165, device='cuda:0') Acc:  tensor(0.3996, device='cuda:0')\n",
      "881 loss:  tensor(2.4148, device='cuda:0') Acc:  tensor(0.4012, device='cuda:0')\n",
      "882 loss:  tensor(2.4168, device='cuda:0') Acc:  tensor(0.3994, device='cuda:0')\n",
      "882 loss:  tensor(2.4147, device='cuda:0') Acc:  tensor(0.4016, device='cuda:0')\n",
      "883 loss:  tensor(2.4174, device='cuda:0') Acc:  tensor(0.3987, device='cuda:0')\n",
      "883 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4018, device='cuda:0')\n",
      "884 loss:  tensor(2.4161, device='cuda:0') Acc:  tensor(0.3998, device='cuda:0')\n",
      "884 loss:  tensor(2.4148, device='cuda:0') Acc:  tensor(0.4009, device='cuda:0')\n",
      "885 loss:  tensor(2.4167, device='cuda:0') Acc:  tensor(0.3990, device='cuda:0')\n",
      "885 loss:  tensor(2.4148, device='cuda:0') Acc:  tensor(0.4012, device='cuda:0')\n",
      "886 loss:  tensor(2.4165, device='cuda:0') Acc:  tensor(0.3997, device='cuda:0')\n",
      "886 loss:  tensor(2.4145, device='cuda:0') Acc:  tensor(0.4015, device='cuda:0')\n",
      "887 loss:  tensor(2.4167, device='cuda:0') Acc:  tensor(0.3993, device='cuda:0')\n",
      "887 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4023, device='cuda:0')\n",
      "888 loss:  tensor(2.4163, device='cuda:0') Acc:  tensor(0.3996, device='cuda:0')\n",
      "888 loss:  tensor(2.4149, device='cuda:0') Acc:  tensor(0.4008, device='cuda:0')\n",
      "889 loss:  tensor(2.4158, device='cuda:0') Acc:  tensor(0.3998, device='cuda:0')\n",
      "889 loss:  tensor(2.4145, device='cuda:0') Acc:  tensor(0.4015, device='cuda:0')\n",
      "890 loss:  tensor(2.4162, device='cuda:0') Acc:  tensor(0.4000, device='cuda:0')\n",
      "890 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4019, device='cuda:0')\n",
      "891 loss:  tensor(2.4159, device='cuda:0') Acc:  tensor(0.4001, device='cuda:0')\n",
      "891 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4017, device='cuda:0')\n",
      "892 loss:  tensor(2.4152, device='cuda:0') Acc:  tensor(0.4011, device='cuda:0')\n",
      "892 loss:  tensor(2.4138, device='cuda:0') Acc:  tensor(0.4022, device='cuda:0')\n",
      "893 loss:  tensor(2.4166, device='cuda:0') Acc:  tensor(0.3995, device='cuda:0')\n",
      "893 loss:  tensor(2.4144, device='cuda:0') Acc:  tensor(0.4016, device='cuda:0')\n",
      "894 loss:  tensor(2.4159, device='cuda:0') Acc:  tensor(0.3998, device='cuda:0')\n",
      "894 loss:  tensor(2.4133, device='cuda:0') Acc:  tensor(0.4023, device='cuda:0')\n",
      "895 loss:  tensor(2.4157, device='cuda:0') Acc:  tensor(0.4005, device='cuda:0')\n",
      "895 loss:  tensor(2.4133, device='cuda:0') Acc:  tensor(0.4025, device='cuda:0')\n",
      "896 loss:  tensor(2.4155, device='cuda:0') Acc:  tensor(0.4005, device='cuda:0')\n",
      "896 loss:  tensor(2.4137, device='cuda:0') Acc:  tensor(0.4025, device='cuda:0')\n",
      "897 loss:  tensor(2.4148, device='cuda:0') Acc:  tensor(0.4013, device='cuda:0')\n",
      "897 loss:  tensor(2.4137, device='cuda:0') Acc:  tensor(0.4019, device='cuda:0')\n",
      "898 loss:  tensor(2.4148, device='cuda:0') Acc:  tensor(0.4011, device='cuda:0')\n",
      "898 loss:  tensor(2.4136, device='cuda:0') Acc:  tensor(0.4025, device='cuda:0')\n",
      "899 loss:  tensor(2.4159, device='cuda:0') Acc:  tensor(0.4002, device='cuda:0')\n",
      "899 loss:  tensor(2.4133, device='cuda:0') Acc:  tensor(0.4020, device='cuda:0')\n",
      "900 loss:  tensor(2.4158, device='cuda:0') Acc:  tensor(0.4006, device='cuda:0')\n",
      "900 loss:  tensor(2.4132, device='cuda:0') Acc:  tensor(0.4028, device='cuda:0')\n",
      "901 loss:  tensor(2.4153, device='cuda:0') Acc:  tensor(0.4002, device='cuda:0')\n",
      "901 loss:  tensor(2.4132, device='cuda:0') Acc:  tensor(0.4023, device='cuda:0')\n",
      "902 loss:  tensor(2.4146, device='cuda:0') Acc:  tensor(0.4012, device='cuda:0')\n",
      "902 loss:  tensor(2.4131, device='cuda:0') Acc:  tensor(0.4024, device='cuda:0')\n",
      "903 loss:  tensor(2.4145, device='cuda:0') Acc:  tensor(0.4013, device='cuda:0')\n",
      "903 loss:  tensor(2.4134, device='cuda:0') Acc:  tensor(0.4028, device='cuda:0')\n",
      "904 loss:  tensor(2.4154, device='cuda:0') Acc:  tensor(0.4003, device='cuda:0')\n",
      "904 loss:  tensor(2.4131, device='cuda:0') Acc:  tensor(0.4025, device='cuda:0')\n",
      "905 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4021, device='cuda:0')\n",
      "905 loss:  tensor(2.4125, device='cuda:0') Acc:  tensor(0.4031, device='cuda:0')\n",
      "906 loss:  tensor(2.4147, device='cuda:0') Acc:  tensor(0.4013, device='cuda:0')\n",
      "906 loss:  tensor(2.4129, device='cuda:0') Acc:  tensor(0.4027, device='cuda:0')\n",
      "907 loss:  tensor(2.4139, device='cuda:0') Acc:  tensor(0.4020, device='cuda:0')\n",
      "907 loss:  tensor(2.4127, device='cuda:0') Acc:  tensor(0.4024, device='cuda:0')\n",
      "908 loss:  tensor(2.4143, device='cuda:0') Acc:  tensor(0.4012, device='cuda:0')\n",
      "908 loss:  tensor(2.4127, device='cuda:0') Acc:  tensor(0.4026, device='cuda:0')\n",
      "909 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4023, device='cuda:0')\n",
      "909 loss:  tensor(2.4122, device='cuda:0') Acc:  tensor(0.4035, device='cuda:0')\n",
      "910 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4013, device='cuda:0')\n",
      "910 loss:  tensor(2.4126, device='cuda:0') Acc:  tensor(0.4033, device='cuda:0')\n",
      "911 loss:  tensor(2.4140, device='cuda:0') Acc:  tensor(0.4016, device='cuda:0')\n",
      "911 loss:  tensor(2.4124, device='cuda:0') Acc:  tensor(0.4034, device='cuda:0')\n",
      "912 loss:  tensor(2.4145, device='cuda:0') Acc:  tensor(0.4011, device='cuda:0')\n",
      "912 loss:  tensor(2.4126, device='cuda:0') Acc:  tensor(0.4031, device='cuda:0')\n",
      "913 loss:  tensor(2.4144, device='cuda:0') Acc:  tensor(0.4011, device='cuda:0')\n",
      "913 loss:  tensor(2.4120, device='cuda:0') Acc:  tensor(0.4039, device='cuda:0')\n",
      "914 loss:  tensor(2.4141, device='cuda:0') Acc:  tensor(0.4021, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# for epoach in range(100):\n",
    "epoach = last_epoach\n",
    "while True:\n",
    "# while np.array(acc_rates).sum() / len(acc_rates) < 0.45:\n",
    "    epoach += 1\n",
    "    x_iter, y_iter = restart_iter(args.batch_size)\n",
    "\n",
    "    ep_cnt = 0\n",
    "    acc_loss = []\n",
    "    acc_rates = []\n",
    "    for batch_x, batch_y in zip(x_iter, y_iter):\n",
    "        batch_x, sent_lengths = list(zip(*batch_x))\n",
    "\n",
    "        batch_x = torch.tensor(np.array([np.array(line) for line in batch_x]))\n",
    "        sent_lengths = torch.tensor(sent_lengths)\n",
    "        batch_y = torch.tensor(batch_y)\n",
    "\n",
    "        batch_x = batch_x.to(device)\n",
    "        sent_lengths = sent_lengths.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(batch_x, sent_lengths)\n",
    "        loss = loss_func(y_hat, batch_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_rate = acc(y_hat, batch_y)\n",
    "\n",
    "        ep_cnt += 1\n",
    "        acc_loss.append(loss)\n",
    "        acc_rates.append(acc_rate)\n",
    "        if ep_cnt % 20 == 0:\n",
    "            last_loss, last_avgac = np.array(acc_loss).sum() / len(\n",
    "                acc_loss), np.array(acc_rates).sum() / len(acc_rates)\n",
    "            print(epoach, \"loss: \", last_loss.data, \"Acc: \", last_avgac)\n",
    "\n",
    "            writer.add_scalar('loss:', last_loss,\n",
    "                              epoach + 0.32 * (ep_cnt % 20))\n",
    "            writer.add_scalar('avg acc:', last_avgac,\n",
    "                              epoach + 0.32 * (ep_cnt % 20))\n",
    "\n",
    "            acc_loss = []\n",
    "            acc_rates = []\n",
    "\n",
    "            # Save:\n",
    "            torch.save(model.state_dict(), f=args.model_path)\n",
    "#             os.system('clear')\n",
    "\n",
    "#     loss.backward(retain_graph=True)\n",
    "\n",
    "        last_epoach = epoach\n",
    "    \n",
    "        with open('./manual_trainLog.log','a') as f:\n",
    "            f.write(last_epoch, last_loss, last_avgac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def predict_to_sent(result):\n",
    "#     return [''.join([vocab.vocab_rdict[tkid.tolist()] for tkid in line]) for line in result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
